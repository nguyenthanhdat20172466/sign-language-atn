{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3120e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pyttsx3\n",
    "#engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c03923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 48, 48, 16)        448       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 46, 46, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 44, 44, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 22, 22, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 20, 20, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 18, 18, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 2, 2, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,697\n",
      "Trainable params: 156,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'C:\\Users\\84396\\Desktop\\Sign-Language-Recognition-main\\new_model_20ep3.h5')\n",
    "#model = tf.keras.models.load_model(r'C:\\Users\\84396\\Desktop\\Sign-Language-Recognition-main\\new_model_20.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376d3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Nothing']\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\84396\\Desktop\\Sign-Language-Recognition-main\\dataset\\train'\n",
    "#getting the labels form data directory\n",
    "labels = sorted(os.listdir(data_dir))\n",
    "labels[-1] = 'Nothing'\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc0e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\84396\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\84396\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087ec741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    " \n",
    "print(cv2.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe2a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    cv2.imshow('webcam', frame)\n",
    "    if cv2.waitKey(1)&0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f80cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('./Gesture Image Data/B/1.jpg')\n",
    "a = cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"img\", img)\n",
    "\n",
    "img = img/255\n",
    "#make predication about the current frame\n",
    "prediction = model.predict(img.reshape(1,50,50,3))\n",
    "char_index = np.argmax(prediction)\n",
    "#print(char_index,prediction[0,char_index]*100)\n",
    "confidence = round(prediction[0,char_index]*100, 1)\n",
    "predicted_char = labels[char_index]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "fontScale = 1\n",
    "color = (0,255,255)\n",
    "thickness = 2\n",
    "#writing the predicted char and its confidence percentage to the frame\n",
    "msg = predicted_char +', Conf: ' +str(confidence)+' %'\n",
    "cv2.putText(a, msg, (80, 80), font, fontScale, color, thickness)\n",
    "cv2.imshow(\"a\", a)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78349183",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "a = cv2.imread(\"american_sign_language.jpg\",0)\n",
    "a = cv2.resize(a, (600,300))\n",
    "while(True):\n",
    "    _ , frame = cap.read()\n",
    "    #frame = cv2.flip(frame, 1)\n",
    "    cv2.rectangle(frame, (100, 100), (300, 300), (0, 0, 255), 5) \n",
    "    #region of intrest\n",
    "    roi = frame[100:300, 100:300]\n",
    "    img = cv2.resize(roi, (50, 50))\n",
    "    cv2.imshow('roi', roi)\n",
    "    img = img/255\n",
    "    prediction = model.predict(img.reshape(1,50,50,3))\n",
    "    char_index = np.argmax(prediction)\n",
    "    confidence = round(prediction[0,char_index]*100, 1)\n",
    "    predicted_char = labels[char_index]\n",
    "    font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    fontScale = 1\n",
    "    color = (0,255,255)\n",
    "    thickness = 2\n",
    "    #writing the predicted char and its confidence percentage to the frame\n",
    "    msg = predicted_char +', Conf: ' +str(confidence)+' %'\n",
    "    cv2.putText(frame, msg, (80, 80), font, fontScale, color, thickness)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow(\"áº£nh\", a)\n",
    "    #close the camera when press 'q'\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):  # Bam q de thoat\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edcade9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
